<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>About me | Marius Le Chapelier&#39;s website</title>
<meta name="keywords" content="">
<meta name="description" content="Hi! I&rsquo;m Marius. ðŸ‘‹ I&rsquo;m a research engineer at Inria Paris, where I study human interactions through the prism of AI and, especially, Natural Langage Processing (NLP) applied to human dialogue. I&rsquo;m part of the the Articulab, within the Almanach team, our work contributes to theoretical research in cognitive science, linguistics, artificial intelligence and other disciplines.
Dialogue is a complex interaction, because it involves a lot of various actions happening at the same time.">
<meta name="author" content="Marius">
<link rel="canonical" href="http://localhost:1313/about/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.54405a410796490bc874ab6181fac9b675753cc2b91375d8f882566459eca428.css" integrity="sha256-VEBaQQeWSQvIdKthgfrJtnV1PMK5E3XY&#43;IJWZFnspCg=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/about/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
  

<meta property="og:title" content="About me" />
<meta property="og:description" content="Hi! I&rsquo;m Marius. ðŸ‘‹ I&rsquo;m a research engineer at Inria Paris, where I study human interactions through the prism of AI and, especially, Natural Langage Processing (NLP) applied to human dialogue. I&rsquo;m part of the the Articulab, within the Almanach team, our work contributes to theoretical research in cognitive science, linguistics, artificial intelligence and other disciplines.
Dialogue is a complex interaction, because it involves a lot of various actions happening at the same time." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/about/" /><meta property="article:section" content="" />
<meta property="article:published_time" content="2024-07-22T12:15:22+02:00" />
<meta property="article:modified_time" content="2024-07-22T12:15:22+02:00" /><meta property="og:site_name" content="MariusLeChapelier&#39;s website" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="About me"/>
<meta name="twitter:description" content="Hi! I&rsquo;m Marius. ðŸ‘‹ I&rsquo;m a research engineer at Inria Paris, where I study human interactions through the prism of AI and, especially, Natural Langage Processing (NLP) applied to human dialogue. I&rsquo;m part of the the Articulab, within the Almanach team, our work contributes to theoretical research in cognitive science, linguistics, artificial intelligence and other disciplines.
Dialogue is a complex interaction, because it involves a lot of various actions happening at the same time."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "About me",
      "item": "http://localhost:1313/about/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "About me",
  "name": "About me",
  "description": "Hi! I\u0026rsquo;m Marius. ðŸ‘‹ I\u0026rsquo;m a research engineer at Inria Paris, where I study human interactions through the prism of AI and, especially, Natural Langage Processing (NLP) applied to human dialogue. I\u0026rsquo;m part of the the Articulab, within the Almanach team, our work contributes to theoretical research in cognitive science, linguistics, artificial intelligence and other disciplines.\nDialogue is a complex interaction, because it involves a lot of various actions happening at the same time.",
  "keywords": [
    
  ],
  "articleBody": "Hi! Iâ€™m Marius. ðŸ‘‹ Iâ€™m a research engineer at Inria Paris, where I study human interactions through the prism of AI and, especially, Natural Langage Processing (NLP) applied to human dialogue. Iâ€™m part of the the Articulab, within the Almanach team, our work contributes to theoretical research in cognitive science, linguistics, artificial intelligence and other disciplines.\nDialogue is a complex interaction, because it involves a lot of various actions happening at the same time. These actions form an exchange of signals of different types (voice, gesture, facial expression, etc), scales (turn, sentence, word or even shorter) and time domain (continuous or discrete) that are all interrelated.\nWe generally distinguish 3 types of signals, 3 modalities :\nVerbal (semantic information) Vocal (prosody, intonation, etc) Non-Verbal (gesture, facial expression, etc) It has been shown in multiple past research that the study of the relationship between these modalities is essential for a better understanding of human interaction, and that their synergy benefits greatly the modeling of such interaction. Our interest is to take forward the recent advances on training multimodal neural networks models to understand or generate human-like interactions.\nIn this context, Iâ€™m currently working on a real-time multimodal dialogue system and embodied conversational agent. This project is a sequel of Articulabâ€™s previous SARA. The system must be able to have a dialogue with the user, by having the capacity, in real-time, to process the userâ€™s multimodal signals : vocal (capturing userâ€™s voice with a microphone), verbal (extracting semantic information from userâ€™s transcription), non-verbal (capturing gesture, facial expression with a camera), and to generate similar signals through an avatar.\n",
  "wordCount" : "266",
  "inLanguage": "en",
  "datePublished": "2024-07-22T12:15:22+02:00",
  "dateModified": "2024-07-22T12:15:22+02:00",
  "author":{
    "@type": "Person",
    "name": "Marius"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/about/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Marius Le Chapelier's website",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Marius Le Chapelier&#39;s website (Alt + H)">Marius Le Chapelier&#39;s website</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/about" title="About">
                    <span class="active">About</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      About me
    </h1>
  </header> 
  <div class="post-content"><h2 id="hi-im-marius-">Hi! I&rsquo;m Marius. ðŸ‘‹<a hidden class="anchor" aria-hidden="true" href="#hi-im-marius-">#</a></h2>
<p>I&rsquo;m a research engineer at <a href="https://www.inria.fr/en">Inria Paris</a>, where I study human interactions through the prism of AI and, especially, <strong>Natural Langage Processing (NLP)</strong> applied to <strong>human dialogue</strong>. I&rsquo;m part of the the <a href="https://articulab.hcii.cs.cmu.edu/">Articulab</a>, within the <a href="https://almanach.inria.fr/index-en.html">Almanach</a> team, our work contributes to theoretical research in cognitive science, linguistics, artificial intelligence and other disciplines.</p>
<p>Dialogue is a complex interaction, because it involves a lot of various actions happening at the same time. These actions form an exchange of signals of different types (voice, gesture, facial expression, etc), scales (turn, sentence, word or even shorter) and time domain (continuous or discrete) that are all interrelated.</p>
<p>We generally distinguish 3 types of signals, 3 <strong>modalities</strong> :</p>
<ul>
<li>Verbal (semantic information)</li>
<li>Vocal (prosody, intonation, etc)</li>
<li>Non-Verbal (gesture, facial expression, etc)</li>
</ul>
<p>It has been shown in multiple past research that the study of the relationship between these modalities is essential for a better understanding of human interaction, and that their synergy benefits greatly the modeling of such interaction. Our interest is to take forward the recent advances on training multimodal neural networks models to understand or generate human-like interactions.</p>
<p>In this context, I&rsquo;m currently working on a <strong>real-time multimodal dialogue system</strong> and <strong>embodied conversational agent</strong>. This project is a sequel of Articulab&rsquo;s previous <a href="https://articulab.hcii.cs.cmu.edu/projects/sara/"><strong>SARA</strong></a>. The system must be able to have a dialogue with the user, by having the capacity, in real-time, to process the user&rsquo;s multimodal signals : vocal (capturing user&rsquo;s voice with a microphone), verbal (extracting semantic information from user&rsquo;s transcription), non-verbal (capturing gesture, facial expression with a camera), and to generate similar signals through an avatar.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Marius Le Chapelier&#39;s website</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
