---
title: 'About me'
date: 2024-07-22T12:15:22+02:00
draft: false
ShowToc: false
ShowReadingTime: false
ShowBreadCrumbs: false
hidemeta: true
---

## Hi! I'm Marius. ðŸ‘‹

I'm a research engineer at [Inria Paris](https://www.inria.fr/en), where I study human interactions through the prism of AI and, especially, **Natural Langage Processing (NLP)** applied to **human dialogue**. I'm part of the the [Articulab](https://articulab.hcii.cs.cmu.edu/), within the [Almanach](https://almanach.inria.fr/index-en.html) team, our work contributes to theoretical research in cognitive science, linguistics, artificial intelligence and other disciplines.

Dialogue is a complex interaction, because it involves a lot of various actions happening at the same time. These actions form an exchange of signals of different types (voice, gesture, facial expression, etc), scales (turn, sentence, word or even shorter) and time domain (continuous or discrete) that are all interrelated.

We generally distinguish 3 types of signals, 3 **modalities** :

- Verbal (semantic information)
- Vocal (prosody, intonation, etc)
- Non-Verbal (gesture, facial expression, etc)

It has been shown in multiple past research that the study of the relationship between these modalities is essential for a better understanding of human interaction, and that their synergy benefits greatly the modeling of such interaction. Our interest is to take forward the recent advances on training multimodal neural networks models to understand or generate human-like interactions.

In this context, I'm currently working on a **real-time multimodal dialogue system** and **embodied conversational agent**. This project is a sequel of Articulab's previous [**SARA**](https://articulab.hcii.cs.cmu.edu/projects/sara/). The system must be able to have a dialogue with the user, by having the capacity, in real-time, to process the user's multimodal signals : vocal (capturing user's voice with a microphone), verbal (extracting semantic information from user's transcription), non-verbal (capturing gesture, facial expression with a camera), and to generate similar signals through an avatar.
